{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction SRT CookBook is available at https://maxlovic.github.io/srtcookbook/ . The purpose of the resource is to provide more in-depth technical documentaion on the SRT protocol and library. Useful Links UDT Documentation","title":"Introduction"},{"location":"#introduction","text":"SRT CookBook is available at https://maxlovic.github.io/srtcookbook/ . The purpose of the resource is to provide more in-depth technical documentaion on the SRT protocol and library.","title":"Introduction"},{"location":"#useful-links","text":"UDT Documentation","title":"Useful Links"},{"location":"faq/","text":"FAQ What applications support SRT? Open source: srt-live-transmit, FFmpeg, WireShark, GStreamer Corporate: Haivision Media Gateway, Haivision KB, Haivision Makito X I get error messages \"tsbpd wrap period begins/ends\". What does it mean? Messages about TSBPD wrap period are informational. These are not errors. SRT just informs that the timer used to track packets is close to overflow and is ready to be reset. There is nothing you should do about that. It is just to inform about this situation. For more information please see the TSBPD Wrapping Period section. Issues on GitHub: #642 . I get error messages \"No room to store incoming packet...\" What does it mean? This error message is usually related to the buffer sizes. See also #703. The Default receiver buffer size is approximately 96 Mbits. This buffer should store all the packets within the specified latency, and also have some space for the application to read (FFmpeg). You might probably need to increase the buffer size, by appending to the following URI \"srt://0.0.0.0:9999?pkt_size=1316&mode=listener\" the following querry values can be added: sndbuf - Send buffer size (in bytes) rcvbuf - Receive buffer size (in bytes) Other FFmpeg SRT URI options can be found here .","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#what-applications-support-srt","text":"Open source: srt-live-transmit, FFmpeg, WireShark, GStreamer Corporate: Haivision Media Gateway, Haivision KB, Haivision Makito X","title":"What applications support SRT?"},{"location":"faq/#i-get-error-messages-tsbpd-wrap-period-beginsends-what-does-it-mean","text":"Messages about TSBPD wrap period are informational. These are not errors. SRT just informs that the timer used to track packets is close to overflow and is ready to be reset. There is nothing you should do about that. It is just to inform about this situation. For more information please see the TSBPD Wrapping Period section. Issues on GitHub: #642 .","title":"I get error messages \"tsbpd wrap period begins/ends\". What does it mean?"},{"location":"faq/#i-get-error-messages-no-room-to-store-incoming-packet-what-does-it-mean","text":"This error message is usually related to the buffer sizes. See also #703. The Default receiver buffer size is approximately 96 Mbits. This buffer should store all the packets within the specified latency, and also have some space for the application to read (FFmpeg). You might probably need to increase the buffer size, by appending to the following URI \"srt://0.0.0.0:9999?pkt_size=1316&mode=listener\" the following querry values can be added: sndbuf - Send buffer size (in bytes) rcvbuf - Receive buffer size (in bytes) Other FFmpeg SRT URI options can be found here .","title":"I get error messages \"No room to store incoming packet...\" What does it mean?"},{"location":"apps/ffmpeg/","text":"FFmpeg FFmpeg supports SRT protocol out of the box. But it needs to be built with -enable-protocol=libsrt to include SRT. Refer to FFmpeg's Compilation Guide for build instructions for your platform. A list of the available protocols can be determined by calling ffmpeg -protocols . \"srt\" (or \"libsrt\") should be listed both as an input, and as an output protocol. Once SRT is available, an SRT output can be specified like this: \"srt://<destination_ip>:<destination_port>\" It would be a good idea to use MPEG-TS as a container -f mpegts . ffplay should be able to play SRT streaming with ffplay srt://<ip>:<port> . Piping can be used as well like this: srt-live-transmit srt://<ip>:<port> file://con | ffplay -f mpegts - Please note the issue #407 . Or pipe via UDP socket on a localhost: srt-live-transmit srt://<ip>:<port> udp://127.0.0.1:<portB> ffplay udp://127.0.0.1:<portB> -f mpegts In the latest case the -f mpegts argument is optional. Note! -re option will slow down the reading: Read input at native frame rate. Mainly used to simulate a grab device, or live input stream (e.g. when reading from a file). Should not be used with ... live input streams (where it can cause packet loss). By default ffmpeg attempts to read the input(s) as fast as possible. This option will slow down the reading of the input(s) to the native frame rate of the input(s). It is useful for real-time output (e.g. live streaming). FFmpeg example grabbing X11 desktop screen and streaming to SRT ffmpeg -f x11grab -follow_mouse centered -r 25 -s cif -i :0.0 \\ -f mpegts srt://<target_ip>:<target_port> FFmpeg example with SMPTE bars test video source ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"srt://127.0.0.1:4200?pkt_size=1316\" Example with FFmpeg and srt-live-transmit Send to UDP localhost port 5000 ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"udp://127.0.0.1:5000?pkt_size=1316\" Transmit from UDP to SRT destination ./srt-live-transmit udp://:5000 srt://<ip>:<port>?mode=rendezvous Receive with SRT ./srt-live-transmit srt://<ip>:<port>?mode=rendezvous file://con > ./received.ts Receive srt and pass to dev/nul `./ffmpeg -i srt://<ip>:<port> -f null /dev/null`","title":"FFmpeg"},{"location":"apps/ffmpeg/#ffmpeg","text":"FFmpeg supports SRT protocol out of the box. But it needs to be built with -enable-protocol=libsrt to include SRT. Refer to FFmpeg's Compilation Guide for build instructions for your platform. A list of the available protocols can be determined by calling ffmpeg -protocols . \"srt\" (or \"libsrt\") should be listed both as an input, and as an output protocol. Once SRT is available, an SRT output can be specified like this: \"srt://<destination_ip>:<destination_port>\" It would be a good idea to use MPEG-TS as a container -f mpegts . ffplay should be able to play SRT streaming with ffplay srt://<ip>:<port> . Piping can be used as well like this: srt-live-transmit srt://<ip>:<port> file://con | ffplay -f mpegts - Please note the issue #407 . Or pipe via UDP socket on a localhost: srt-live-transmit srt://<ip>:<port> udp://127.0.0.1:<portB> ffplay udp://127.0.0.1:<portB> -f mpegts In the latest case the -f mpegts argument is optional. Note! -re option will slow down the reading: Read input at native frame rate. Mainly used to simulate a grab device, or live input stream (e.g. when reading from a file). Should not be used with ... live input streams (where it can cause packet loss). By default ffmpeg attempts to read the input(s) as fast as possible. This option will slow down the reading of the input(s) to the native frame rate of the input(s). It is useful for real-time output (e.g. live streaming).","title":"FFmpeg"},{"location":"apps/ffmpeg/#ffmpeg-example-grabbing-x11-desktop-screen-and-streaming-to-srt","text":"ffmpeg -f x11grab -follow_mouse centered -r 25 -s cif -i :0.0 \\ -f mpegts srt://<target_ip>:<target_port>","title":"FFmpeg example grabbing X11 desktop screen and streaming to SRT"},{"location":"apps/ffmpeg/#ffmpeg-example-with-smpte-bars-test-video-source","text":"ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"srt://127.0.0.1:4200?pkt_size=1316\"","title":"FFmpeg example with SMPTE bars test video source"},{"location":"apps/ffmpeg/#example-with-ffmpeg-and-srt-live-transmit","text":"Send to UDP localhost port 5000 ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"udp://127.0.0.1:5000?pkt_size=1316\" Transmit from UDP to SRT destination ./srt-live-transmit udp://:5000 srt://<ip>:<port>?mode=rendezvous Receive with SRT ./srt-live-transmit srt://<ip>:<port>?mode=rendezvous file://con > ./received.ts Receive srt and pass to dev/nul `./ffmpeg -i srt://<ip>:<port> -f null /dev/null`","title":"Example with FFmpeg and srt-live-transmit"},{"location":"apps/gstreamer-plugin/","text":"GStreamer Starting from ver. 1.14 GStreamer supports SRT (see the v.1.14 release notes ). See the SRT plugin for GStreamer on git . Using GStreamer and SRT to set up a screensharing Based on the description in #7 . Note that the commands are likely to change slightly for gstreamer 1.16 (see this issue ). If you don't want to build GSteamer, SRT, and all the plugins from source or don't have a distribution that has 1.14 readily available, you can use nix to reproduce what is shown further. Simply install nix ; then use the command bellow to open a shell where the following commands work. NIX_PATH=nixpkgs=https://github.com/nh2/nixpkgs/archive/a94ff5f6aaa.tar.gz \\ nix-shell -p gst_all_1.gstreamer \\ -p gst_all_1.gst-plugins-good -p gst_all_1.gst-plugins-base \\ -p gst_all_1.gst-plugins-bad \\ -p gst_all_1.gst-plugins-ugly -p gst_all_1.gst-libav Sender server Set up a sender server that will grab a source raw video from a desktop or a webcam, encode it with x.264 (H.264/AVC) encoder, pack it in MPEG-TS ( more info about live streaming ). Then pipe it into the SRT sink that sends it over the network to the receiver client. The streaming URI should looks like uri=srt://<ip>:<port> . In the examples below the streaming is sent to port 888 on a localhost by specifying uri=srt://0.0.0.0:8888 . For screensharing (Linux with X Display) The ximagesrc GStreamer plugin can be used to capture X Display and create raw RGB video. Refer to ximagesrc RM for configuration options. /usr/bin/time gst-launch-1.0 ximagesrc startx=0 show-pointer=true use-damage=0 \\ ! videoconvert \\ ! x264enc bitrate=32000 tune=zerolatency speed-preset=veryfast \\ byte-stream=true threads=1 key-int-max=15 \\ intra-refresh=true ! video/x-h264, profile=baseline, framerate=30/1 ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100 For webcam images The v4l2src GStreamer plugin can be used to capture video from v4l2 devices, like webcams and TV cards. Refer to v4l2src RM for further information. /usr/bin/time gst-launch-1.0 v4l2src ! videoconvert \\ ! x264enc bitrate=8000 tune=zerolatency speed-preset=superfast \\ byte-stream=true threads=1 key-int-max=15 intra-refresh=true \\ ! video/x-h264, profile=baseline ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100 Notes The decodebin can also be used to configure settings automatically. Using explicit pipeline elements here make it possible to tune the settings when needed. A use of time helps to determine when the thread is capped at 100%, while the the thread=1 parameter makes the encoding use only one thread. Remove threads=1 to allow multiple cores, or cjange the speed-preset to reduce CPU load. The timeout setting can be tuned. A recommended timeout is 2x-2.5x of the expected roundtrip time. The password functionality works as well, but only if a password is >= 10 characters long; otherwise it's completely ignored. See this bug of GStreamer. Receiver client A client connection over SRT to the server with URI srt://127.0.0.1:8888 (localhost) or a remote server is set up. URI syntax is srt://<ip>:<port> . Then MPEG-TS demuxer and video decoder is used to get a decompressed video, that goes to a playback plugin autovideosink . Note that multiple clients can connect to the server started earlier. gst-launch-1.0 srtclientsrc uri=srt://127.0.0.1:8888 ! tsdemux ! h264parse ! video/x-h264 ! avdec_h264 ! autovideosink sync=false This works over both the internet and localhost. Useful Links Oliver Cr\u00eate. SRT in GStreamer . 2018","title":"GStreamer"},{"location":"apps/gstreamer-plugin/#gstreamer","text":"Starting from ver. 1.14 GStreamer supports SRT (see the v.1.14 release notes ). See the SRT plugin for GStreamer on git .","title":"GStreamer"},{"location":"apps/gstreamer-plugin/#using-gstreamer-and-srt-to-set-up-a-screensharing","text":"Based on the description in #7 . Note that the commands are likely to change slightly for gstreamer 1.16 (see this issue ). If you don't want to build GSteamer, SRT, and all the plugins from source or don't have a distribution that has 1.14 readily available, you can use nix to reproduce what is shown further. Simply install nix ; then use the command bellow to open a shell where the following commands work. NIX_PATH=nixpkgs=https://github.com/nh2/nixpkgs/archive/a94ff5f6aaa.tar.gz \\ nix-shell -p gst_all_1.gstreamer \\ -p gst_all_1.gst-plugins-good -p gst_all_1.gst-plugins-base \\ -p gst_all_1.gst-plugins-bad \\ -p gst_all_1.gst-plugins-ugly -p gst_all_1.gst-libav","title":"Using GStreamer and SRT to set up a screensharing"},{"location":"apps/gstreamer-plugin/#sender-server","text":"Set up a sender server that will grab a source raw video from a desktop or a webcam, encode it with x.264 (H.264/AVC) encoder, pack it in MPEG-TS ( more info about live streaming ). Then pipe it into the SRT sink that sends it over the network to the receiver client. The streaming URI should looks like uri=srt://<ip>:<port> . In the examples below the streaming is sent to port 888 on a localhost by specifying uri=srt://0.0.0.0:8888 .","title":"Sender server"},{"location":"apps/gstreamer-plugin/#for-screensharing-40linux-with-x-display41","text":"The ximagesrc GStreamer plugin can be used to capture X Display and create raw RGB video. Refer to ximagesrc RM for configuration options. /usr/bin/time gst-launch-1.0 ximagesrc startx=0 show-pointer=true use-damage=0 \\ ! videoconvert \\ ! x264enc bitrate=32000 tune=zerolatency speed-preset=veryfast \\ byte-stream=true threads=1 key-int-max=15 \\ intra-refresh=true ! video/x-h264, profile=baseline, framerate=30/1 ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100","title":"For screensharing (Linux with X Display)"},{"location":"apps/gstreamer-plugin/#for-webcam-images","text":"The v4l2src GStreamer plugin can be used to capture video from v4l2 devices, like webcams and TV cards. Refer to v4l2src RM for further information. /usr/bin/time gst-launch-1.0 v4l2src ! videoconvert \\ ! x264enc bitrate=8000 tune=zerolatency speed-preset=superfast \\ byte-stream=true threads=1 key-int-max=15 intra-refresh=true \\ ! video/x-h264, profile=baseline ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100","title":"For webcam images"},{"location":"apps/gstreamer-plugin/#notes","text":"The decodebin can also be used to configure settings automatically. Using explicit pipeline elements here make it possible to tune the settings when needed. A use of time helps to determine when the thread is capped at 100%, while the the thread=1 parameter makes the encoding use only one thread. Remove threads=1 to allow multiple cores, or cjange the speed-preset to reduce CPU load. The timeout setting can be tuned. A recommended timeout is 2x-2.5x of the expected roundtrip time. The password functionality works as well, but only if a password is >= 10 characters long; otherwise it's completely ignored. See this bug of GStreamer.","title":"Notes"},{"location":"apps/gstreamer-plugin/#receiver-client","text":"A client connection over SRT to the server with URI srt://127.0.0.1:8888 (localhost) or a remote server is set up. URI syntax is srt://<ip>:<port> . Then MPEG-TS demuxer and video decoder is used to get a decompressed video, that goes to a playback plugin autovideosink . Note that multiple clients can connect to the server started earlier. gst-launch-1.0 srtclientsrc uri=srt://127.0.0.1:8888 ! tsdemux ! h264parse ! video/x-h264 ! avdec_h264 ! autovideosink sync=false This works over both the internet and localhost.","title":"Receiver client"},{"location":"apps/gstreamer-plugin/#useful-links","text":"Oliver Cr\u00eate. SRT in GStreamer . 2018","title":"Useful Links"},{"location":"apps/obs-studio/","text":"OBS Studio OBS Studio is a free and open source software for video recording and live streaming. Starting from version ?? It supports SRT.","title":"OBS Studio"},{"location":"apps/obs-studio/#obs-studio","text":"OBS Studio is a free and open source software for video recording and live streaming. Starting from version ?? It supports SRT.","title":"OBS Studio"},{"location":"apps/vlc-media-player/","text":"VLC Media Player VLC media player supports SRT as an input (starting from version 3.0?). SRT access module source code: link . To open an SRT stream go to the menu \"Media\" -> \"Open Network Stream\". Specfy the source URI in the format: srt://ip:port . Note that VLC does not parse URI query options, so the parameters passed in a query are ignored. For example, srt://ip:port?passphrase=123456789!@ is identical to a simple srt:ip:port . SRT options can be specified on the corresponding property page. Go to the menu \"Tools\" -> \"Preferences\". In the bottom-left corner select \"Show Settings: All\". Select \"SRT\" in the tree node of \"Input Codecs\" -> \"Access modules\".","title":"VLC Media Player"},{"location":"apps/vlc-media-player/#vlc-media-player","text":"VLC media player supports SRT as an input (starting from version 3.0?). SRT access module source code: link . To open an SRT stream go to the menu \"Media\" -> \"Open Network Stream\". Specfy the source URI in the format: srt://ip:port . Note that VLC does not parse URI query options, so the parameters passed in a query are ignored. For example, srt://ip:port?passphrase=123456789!@ is identical to a simple srt:ip:port . SRT options can be specified on the corresponding property page. Go to the menu \"Tools\" -> \"Preferences\". In the bottom-left corner select \"Show Settings: All\". Select \"SRT\" in the tree node of \"Input Codecs\" -> \"Access modules\".","title":"VLC Media Player"},{"location":"apps/wireshark/","text":"Wireshark","title":"Wireshark"},{"location":"apps/wireshark/#wireshark","text":"","title":"Wireshark"},{"location":"getting-started/build-on-windows/","text":"Build on Windows Using NuGet 1. Download and install OpenSSL for Windows. The 64-bit package can be downloaded from here: Win64OpenSSL_Light-1_1_1c.exe . (Note that the last letter or version number may be changed and older versions no longer available. If this isn't found, check here: http://slproweb.com/products/Win32OpenSSL.html ) It's expected to be installed in C:\\Program Files\\OpenSSL-Win64 . Add this path to the user's or system's environment variable PATH . 2. Install Pthreads for Windows nuget install cinegy.pthreads-win64 -version 2.9.1.17 -OutputDirectory C:\\pthread-win32 3. Install cmake for Windows. CMake dowload page . The CMake GUI will help you configure the project. 4. Generate Visual Studio Solution. Assuming you are currently in the cloned repo. mkdir _build & cd _build cmake ../ -G\"Visual Studio 16 2019\" -A x64 -DPTHREAD_INCLUDE_DIR=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\sources\" -DPTHREAD_LIBRARY=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\runtimes\\win-x64\\native\\release\\pthread_lib.lib\" cmake --build ./ --config Release CMake will try to find OpenSSL and pthreads. If any of the is not found, you can define the following variables to help CMake find them: OPENSSL_ROOT_DIR=<path to OpenSSL installation> OPENSSL_LIBRARIES=<path to all the openssl libraries to link> OPENSSL_INCLUDE_DIR=<path to the OpenSSL include dir> PTHREAD_INCLUDE_DIR=<path to where pthread.h lies> PTHREAD_LIBRARY=<path to pthread.lib> Using vcpkg","title":"Build on Windows"},{"location":"getting-started/build-on-windows/#build-on-windows","text":"","title":"Build on Windows"},{"location":"getting-started/build-on-windows/#using-nuget","text":"","title":"Using NuGet"},{"location":"getting-started/build-on-windows/#1-download-and-install-openssl-for-windows","text":"The 64-bit package can be downloaded from here: Win64OpenSSL_Light-1_1_1c.exe . (Note that the last letter or version number may be changed and older versions no longer available. If this isn't found, check here: http://slproweb.com/products/Win32OpenSSL.html ) It's expected to be installed in C:\\Program Files\\OpenSSL-Win64 . Add this path to the user's or system's environment variable PATH .","title":"1. Download and install OpenSSL for Windows."},{"location":"getting-started/build-on-windows/#2-install-pthreads-for-windows","text":"nuget install cinegy.pthreads-win64 -version 2.9.1.17 -OutputDirectory C:\\pthread-win32","title":"2. Install Pthreads for Windows"},{"location":"getting-started/build-on-windows/#3-install-cmake-for-windows","text":"CMake dowload page . The CMake GUI will help you configure the project.","title":"3. Install cmake for Windows."},{"location":"getting-started/build-on-windows/#4-generate-visual-studio-solution","text":"Assuming you are currently in the cloned repo. mkdir _build & cd _build cmake ../ -G\"Visual Studio 16 2019\" -A x64 -DPTHREAD_INCLUDE_DIR=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\sources\" -DPTHREAD_LIBRARY=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\runtimes\\win-x64\\native\\release\\pthread_lib.lib\" cmake --build ./ --config Release CMake will try to find OpenSSL and pthreads. If any of the is not found, you can define the following variables to help CMake find them: OPENSSL_ROOT_DIR=<path to OpenSSL installation> OPENSSL_LIBRARIES=<path to all the openssl libraries to link> OPENSSL_INCLUDE_DIR=<path to the OpenSSL include dir> PTHREAD_INCLUDE_DIR=<path to where pthread.h lies> PTHREAD_LIBRARY=<path to pthread.lib>","title":"4. Generate Visual Studio Solution."},{"location":"getting-started/build-on-windows/#using-vcpkg","text":"","title":"Using vcpkg"},{"location":"getting-started/vcpkg-library-manager/","text":"Vcpkg Library Manager SRT is included in vcpkg ( PR 8712 ). Vcpkg is C++ Library Manager for Windows, Linux, and MacOS. There are two options to build SRT using vcpkg . 1. Build SRT with vcpkg Once SRT is added to the list of supported ports of vcpkg, the buld will be: vcpkg install libsrt 2. Build SRT with openssl and pthreads built with vcpkg At the moment it can already be used to simplify SRT build. Vcpkg already has ports for openssl and pthreads , so the build is as easy as vcpkg install openssl vcpkg install pthreads Integrate vcpkg with the build system (CMake will know about packaged installed by vcpkg) vcpkg integrate install Then build SRT: cmake ../ -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_TOOLCHAIN_FILE=[vcpkg root]\\scripts\\buildsystems\\vcpkg.cmake","title":"Vcpkg Library Manager"},{"location":"getting-started/vcpkg-library-manager/#vcpkg-library-manager","text":"SRT is included in vcpkg ( PR 8712 ). Vcpkg is C++ Library Manager for Windows, Linux, and MacOS. There are two options to build SRT using vcpkg .","title":"Vcpkg Library Manager"},{"location":"getting-started/vcpkg-library-manager/#1-build-srt-with-vcpkg","text":"Once SRT is added to the list of supported ports of vcpkg, the buld will be: vcpkg install libsrt","title":"1. Build SRT with vcpkg"},{"location":"getting-started/vcpkg-library-manager/#2-build-srt-with-openssl-and-pthreads-built-with-vcpkg","text":"At the moment it can already be used to simplify SRT build. Vcpkg already has ports for openssl and pthreads , so the build is as easy as vcpkg install openssl vcpkg install pthreads Integrate vcpkg with the build system (CMake will know about packaged installed by vcpkg) vcpkg integrate install Then build SRT: cmake ../ -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_TOOLCHAIN_FILE=[vcpkg root]\\scripts\\buildsystems\\vcpkg.cmake","title":"2. Build SRT with openssl and pthreads built with vcpkg"},{"location":"protocol/","text":"The Protocol The section contains a description of key protocol features.","title":"The Protocol"},{"location":"protocol/#the-protocol","text":"The section contains a description of key protocol features.","title":"The Protocol"},{"location":"protocol/bandwidth-estimation/","text":"Bandwidth Estimation SRT estimates the value of the link capacity. This is done by using a packet pair probing technique. In this technique, the sender sends two back-to-back packets of the same size. Once these two packets arrive at the receiver side, there will be an interval between the two packets. The link capacity can then be determined by B = packet size / interval SRT sends out a packet pair every 16 packets. However, when it happens that there is no 17th packet to be sent out, SRT will still send out the 16th packet, rather than waiting for the next one. In this case, there will be a bigger interval (hence underestimation) at the receiver side. The receiver should use a median filter to detect and discard such values. In addition, other patterns of packet pairs can be used, as long as the receiver has a way to identify the packet pairs. Ningning Hu, Peter Steenkiste. Estimating Available Bandwidth Using Packet Pair Probing . 2002. Yunhong Gu. The UDT Congestion Control Algorithm . 2009.","title":"Bandwidth Estimation"},{"location":"protocol/bandwidth-estimation/#bandwidth-estimation","text":"SRT estimates the value of the link capacity. This is done by using a packet pair probing technique. In this technique, the sender sends two back-to-back packets of the same size. Once these two packets arrive at the receiver side, there will be an interval between the two packets. The link capacity can then be determined by B = packet size / interval SRT sends out a packet pair every 16 packets. However, when it happens that there is no 17th packet to be sent out, SRT will still send out the 16th packet, rather than waiting for the next one. In this case, there will be a bigger interval (hence underestimation) at the receiver side. The receiver should use a median filter to detect and discard such values. In addition, other patterns of packet pairs can be used, as long as the receiver has a way to identify the packet pairs. Ningning Hu, Peter Steenkiste. Estimating Available Bandwidth Using Packet Pair Probing . 2002. Yunhong Gu. The UDT Congestion Control Algorithm . 2009.","title":"Bandwidth Estimation"},{"location":"protocol/events-and-timers/","text":"Control Events and Timers Timers LastRSP time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), upon receiving a control or data packet. LastRspAck time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), an ACK packet for yet unacknowledged packet is received, and also if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg() . LastSND timer is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), when a control or data packet is sent. A special update happens when a handshake message is sent in response to incomming handshare packet (this does not happen via sendCtrl()). The value is used to trigger sending a KEEPALIVE message. See Sec. Keepalive Messages. NextACK time. NextNAK time. TargetSND time (TargetTime - rename in source code?) is used in the sender only for rate-based packet sending. In UDT draft referred to as SND timer. Events SRT has different events: ACK, NAK, EXP, SND and RSP. Each event has its own period and they are all independent. They use the system time as origins and should process wrapping if the system time wraps. For a certain periodical event E in SRT, suppose the time variable is ET and its period is p. If E is set or reset at system time t0 (ET = t0), then at any time t1, (t1 - ET >= p) is the condition to check if E should be triggered. ACK is used to trigger an acknowledgment (ACK). Its period is set by the congestion control module, otherwise the default value of 10 ms is used (COMM_SYN_INTERVAL or SYN time). However, SRT will send an ACK no longer than every 0.01 second, even though the congestion control does not need timer-based ACK. Here, 0.01 second is defined as the SYN time, or synchronization time, and it affects many of the other timers used in SRT. NAK is used to trigger a negative acknowledgment (NAK). Its period is dynamically updated to RTT + 4 \u00d7 RTTVar + SYN, where RTTVar is the variance of RTT samples. EXP is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) should be used in the implementation. UDT: 4 \u00d7 RTT + RTTVar Note that 4 \u00d7 RTT + RTTVar + SYN is described in the UDT draft (Timers section). However, the formula actually used in the UDT v4 source code is RTT + 4 \u00d7 RTTVar + SYN, which is also used in the SRT (as of v1.3.2). UDT v3 just uses 1 sec timeout. In the rest of this document, a name of a time variable will be used to represent the associated event, the variable itself, or the value of its period, depending on the context. For example, ACK can mean either the ACK event or the value of ACK period. Connection Expiration Default 5 seconds. Can be configured by SRTO_PEERIDLETIMEO. TODO: Add details Describe in more details, as it relies on several timers. EXP Event Processing (Currently just copied from UDT draft). Put all the unacknowledged packets into the sender's loss list. If (ExpCount > 16) and at least 3 seconds has elapsed since that last time when ExpCount is reset to 1, or, 3 minutes has elapsed, close the UDT connection and exit. If the sender's loss list is empty, send a keep-alive packet to the peer side. Increase ExpCount by 1. Acknowledgement Messages There are several types of ACK packets: lite ACK, small ACK and full ACK. The default ACK interval ACKInt is 10 ms ( CUDT::m_ullACKInt_tk ). The Congestion Control module can specify a custom ACK interval by overriding the SrtCongestionControlBase::ACKIntervalMicrosec() . Neither LiveCC, nor FileCC specify this value. NextACK time is set to tcur + ACKInt at the start when SRT socket is created and updated when a connection is established (since SRT v1.3.3, PR #745 ). The value is updated on every ACK packet sent as NextACK = tcur + ACKInt, where ACKInt = CC::ACKInt\u00b5s ? CC::ACKInt\u00b5s : CUDT::ACKInt. ACK packet is sent if tcur > NextACK or if Pktsrcvd >= CC::ACKIntpkts, where CC::ACKIntpkts is specified by the Congestion Control. Neither LiveCC, nor FileCC specify this value. Congestion control can also schedule sending the ACK by setting NextACK = tcur if CC::needsQuickACK() returns true. By default LiveCC returns false, and FileCC returns true if the payload size is less than the maximum size (end of file detection). A lite ACK is sent if Pktsrcvd >= 64 (CC:: SELF_CLOCK_INTERVAL). A full ACK is sent if tcur ACKLast > ACKInt. Otherwise a small ACK is sent. ACK for the same sequence may be sent again if tcur - ACKLast >= RTT + 4 \u00d7 RTTVar (see CUDT::sendCtrl()). Keepalive Messages Keepalive messages in SRT are sent based on the LAST_SND timer. LAST_SND timer is updated by the latest control or data packet sent. A KEEPALIVE message is sent if t >= LAST_SND + KEEPALIVE_PERIOD, where KEEPALIVE_PERIOD = 1 sec. Keepalive messages in UDT are sent based on the EXP timer. EXP event is triggered at t >= N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. If N >= 16, the connection is closed. Otherwise if the senders buffer has unacknowledged packets, they are considered lost, added to the lost list, thus scheduled for retransmission. If the sender's buffer has no unacknowledged packets, a KEEPALIVE control packet is sent.It can be calculated, that for an idle connection a KEEPALIVE is sent every RTT + 4 \u00d7 RTTVar + SYN. NAK Reports Sent by Receiver A negative acknowledgment (NAK) report is special SRT control packet, sent by the receiver back to the sender. The packet holds compressed sequence numbers of packets considered lost by the receiver. There are two possibilities for the receiver to report a loss back to the sender. Triggered by Loss Detection Loss detection is based on Gaps in Sequence Numbers. Detection of a packet loss is triggered with the newly received packet. An offset between the newly arrived packet and the last acknowledged position is calculated. In case the offset is negative, the packet is considered belated, meaning that it was either already acknowledged or dropped by TSBPD as too late to be delivered. Such belated packets are ignored. Documentation states the retransmitted packet is not considered belated Check statistics handling any packets after receiver ACK as belated, regardless of the retransmit flag. Should the re-transmitted packets be ignored? An offset between sequence numbers of the arrived packet and the previously received packet is calculated. If the packet is not the next packet in order, then a loss detection mechanism is triggered. First, a gap in sequence numbers of the consecutively received packets might be due to packet reordering. Sequence numbers that should fill the gap are added to the *RcvLossList* of a socket. Then there is a decision whether a loss report should be sent. A non-zero reorder tolerance (ReorderTolerance <= MaxReorderTolerance) determines if a gap in sequence numbers is allowed. The default value of MaxReorderTolerance is zero, and it can be set with SRTO_LOSSMAXTTL socket option. If ReorderTolerance==0, a loss report is sent immediately for the detected gap. Otherwise, if ReorderTolerance>0, then the detected gap is added to a temporal loss list, with a TTL value equal to current ReorderTolerance value. Each time a DATA packet is received, TTTL of every lost packet in this temporal loss list is decremented by 1. Those packets TODO: Describe ReorderTolerance update logic Example from SRT Periodic NAK Reports showing how a serial loss will be treated. Packets in Transit | Receive Buffer | | Largest sequence number received (4) | New / +---+ +---+ | +---+ +---+---+---+---+---+---+ --- | 9 | --- | 8 | ---> | --->| 7 | + | _ | _ | 4 | 3 | _ | 1 | ---> +---+ +---+ | +---+ | +---+---+---+---+---+---+ | | \\_____/ \\_/ +---+ | +---+ | \\____________/ <--- |NAK| <--- | <---|NAK|-+ Missing packets | 2 | | |5,6| +---+ | +---+ Triggered by Periodic NAK Reports See also SRT Periodic NAK Reports . By default periodic NAK reports are enabled in live mode (SRTO_TRANSTYPE = SRTT_LIVE), and disabled in file mode (SRTO_TRANSTYPE = SRTT_FILE). The functionality is controlled by SRTO_NAKREPORT socket option. NAKtime is the time to send the next periodic NAK report. When t >= NAKtime and the RcvLossList* * is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList* *). | Receive Buffer | | Largest sequence number received (7) | / | +---+---+---+---+---+---+---+ | --->| 7 | _ | _ | 4 | 3 | _ | 1 | ---> | +---+---+---+---+---+---+---+ | | \\_____/ \\_/ | +-----+ | \\____________/ | <-| NAK |-+ Missing packets | |2,5,6| | +-----+ NAKtime is first initialized when a socket is created, and updated after a connection is established (since SRT v1.3.3, PR #745 ). Regularly NAKtime is updated with the last time a periodic NAK report was sent: NAKtime = t + NAKInt . ISSUE #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? Or at least update the time if there are no losses in the *RcvLossList* . where NAKInt is an interval between periodic NAK reports. Minimum NAK interval is NAKIntmin=300 ms, and it is set at the very beginning of the streaming. NAK interval NAKInt is updated after sending a loss report. The new value is NAKInt = RTT + 4 \u00d7 RTTVar . This value is passed to the CC module. FileCC can update NAKInt based on the reported receiving speed Rrcv (packets per second) and the length of the loss list LOSSlen: NAKInt = RTT + 4 \u00d7 RTTVar + LOSSlen \u00d7 106 / Rrcv. LiveCC will update NAKInt by dividing it by 2: LOSSlen: NAKInt = (RTT + 4 \u00d7 RTTVar) / 2. The minimum value is NAKInt = max(NAKInt, NAKIntmin). NAKtime is a time to send the next periodic NAK report. The time is initialized at CUDT::open() and after a connection is established (PR #745 ). NAKtime is updated with the last time a periodic NAK report was sent. ISSUE #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? When t >= NAKtime and the RcvLossList* * is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList* *). Packet Retransmission (Sender) Retransmission Triggered by NAK Report A packet is scheduled for retransmission if a sender receives a NAK report from the receiver. A loss report may be triggered either by loss detection, or by periodic NAK reports (see NAK Reports section above). Blind Retransmission A blind retransmission is an heuristic mechanism of a sender to trigger packet retransmission without receiving a NAK report from the receiver. Fast Retransmission (FASTREXMIT) FASTREXMIT mode is enabled by LiveCC when the receiver is not expected to send periodic NAK reports. A condition is triggered based on the LastRspAck time. Timer-triggered condition: t > N \u00d7 (RTT + 4 \u00d7 RTTVar + 2 \u00d7 SYN) + SYN, where SYN=10 ms, and N is a number of such retransmissions since last ACK (also reset if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg). All unacknowledged packets in the sender's buffer are added to the SndLossList and scheduled for retransmission. FASTREXMIT is not present in UDT. Late Retransmission (LATEREXMIT) TODO: User-defined RTT Describe a scenario with a user-defined RTO value. The LATEREXMIT is the default blind retransmission mode of UDT. LATEREXMIT is triggered by the EXP timer. EXP timer in UDT is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) is used in the implementation. Each time EXP timer is triggered, resend unacknowledged packets currently in the sender's buffer if there are some, otherwise send a KEEPALIVE message. In SRT v1.3.2 and earlier the logic is the same, except that a KEEPALIVE message has its own timer and a timeout of 1 second (see keepalive section above). TODO: Check if excessive KEEPALIVE messages are sent after a retransmission is scheduled.","title":"Control Events and Timers"},{"location":"protocol/events-and-timers/#control-events-and-timers","text":"","title":"Control Events and Timers"},{"location":"protocol/events-and-timers/#timers","text":"LastRSP time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), upon receiving a control or data packet. LastRspAck time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), an ACK packet for yet unacknowledged packet is received, and also if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg() . LastSND timer is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), when a control or data packet is sent. A special update happens when a handshake message is sent in response to incomming handshare packet (this does not happen via sendCtrl()). The value is used to trigger sending a KEEPALIVE message. See Sec. Keepalive Messages. NextACK time. NextNAK time. TargetSND time (TargetTime - rename in source code?) is used in the sender only for rate-based packet sending. In UDT draft referred to as SND timer.","title":"Timers"},{"location":"protocol/events-and-timers/#events","text":"SRT has different events: ACK, NAK, EXP, SND and RSP. Each event has its own period and they are all independent. They use the system time as origins and should process wrapping if the system time wraps. For a certain periodical event E in SRT, suppose the time variable is ET and its period is p. If E is set or reset at system time t0 (ET = t0), then at any time t1, (t1 - ET >= p) is the condition to check if E should be triggered. ACK is used to trigger an acknowledgment (ACK). Its period is set by the congestion control module, otherwise the default value of 10 ms is used (COMM_SYN_INTERVAL or SYN time). However, SRT will send an ACK no longer than every 0.01 second, even though the congestion control does not need timer-based ACK. Here, 0.01 second is defined as the SYN time, or synchronization time, and it affects many of the other timers used in SRT. NAK is used to trigger a negative acknowledgment (NAK). Its period is dynamically updated to RTT + 4 \u00d7 RTTVar + SYN, where RTTVar is the variance of RTT samples. EXP is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) should be used in the implementation. UDT: 4 \u00d7 RTT + RTTVar Note that 4 \u00d7 RTT + RTTVar + SYN is described in the UDT draft (Timers section). However, the formula actually used in the UDT v4 source code is RTT + 4 \u00d7 RTTVar + SYN, which is also used in the SRT (as of v1.3.2). UDT v3 just uses 1 sec timeout. In the rest of this document, a name of a time variable will be used to represent the associated event, the variable itself, or the value of its period, depending on the context. For example, ACK can mean either the ACK event or the value of ACK period.","title":"Events"},{"location":"protocol/events-and-timers/#connection-expiration","text":"Default 5 seconds. Can be configured by SRTO_PEERIDLETIMEO. TODO: Add details Describe in more details, as it relies on several timers. EXP Event Processing (Currently just copied from UDT draft). Put all the unacknowledged packets into the sender's loss list. If (ExpCount > 16) and at least 3 seconds has elapsed since that last time when ExpCount is reset to 1, or, 3 minutes has elapsed, close the UDT connection and exit. If the sender's loss list is empty, send a keep-alive packet to the peer side. Increase ExpCount by 1.","title":"Connection Expiration"},{"location":"protocol/events-and-timers/#acknowledgement-messages","text":"There are several types of ACK packets: lite ACK, small ACK and full ACK. The default ACK interval ACKInt is 10 ms ( CUDT::m_ullACKInt_tk ). The Congestion Control module can specify a custom ACK interval by overriding the SrtCongestionControlBase::ACKIntervalMicrosec() . Neither LiveCC, nor FileCC specify this value. NextACK time is set to tcur + ACKInt at the start when SRT socket is created and updated when a connection is established (since SRT v1.3.3, PR #745 ). The value is updated on every ACK packet sent as NextACK = tcur + ACKInt, where ACKInt = CC::ACKInt\u00b5s ? CC::ACKInt\u00b5s : CUDT::ACKInt. ACK packet is sent if tcur > NextACK or if Pktsrcvd >= CC::ACKIntpkts, where CC::ACKIntpkts is specified by the Congestion Control. Neither LiveCC, nor FileCC specify this value. Congestion control can also schedule sending the ACK by setting NextACK = tcur if CC::needsQuickACK() returns true. By default LiveCC returns false, and FileCC returns true if the payload size is less than the maximum size (end of file detection). A lite ACK is sent if Pktsrcvd >= 64 (CC:: SELF_CLOCK_INTERVAL). A full ACK is sent if tcur ACKLast > ACKInt. Otherwise a small ACK is sent. ACK for the same sequence may be sent again if tcur - ACKLast >= RTT + 4 \u00d7 RTTVar (see CUDT::sendCtrl()).","title":"Acknowledgement Messages"},{"location":"protocol/events-and-timers/#keepalive-messages","text":"Keepalive messages in SRT are sent based on the LAST_SND timer. LAST_SND timer is updated by the latest control or data packet sent. A KEEPALIVE message is sent if t >= LAST_SND + KEEPALIVE_PERIOD, where KEEPALIVE_PERIOD = 1 sec. Keepalive messages in UDT are sent based on the EXP timer. EXP event is triggered at t >= N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. If N >= 16, the connection is closed. Otherwise if the senders buffer has unacknowledged packets, they are considered lost, added to the lost list, thus scheduled for retransmission. If the sender's buffer has no unacknowledged packets, a KEEPALIVE control packet is sent.It can be calculated, that for an idle connection a KEEPALIVE is sent every RTT + 4 \u00d7 RTTVar + SYN.","title":"Keepalive Messages"},{"location":"protocol/events-and-timers/#nak-reports-sent-by-receiver","text":"A negative acknowledgment (NAK) report is special SRT control packet, sent by the receiver back to the sender. The packet holds compressed sequence numbers of packets considered lost by the receiver. There are two possibilities for the receiver to report a loss back to the sender.","title":"NAK Reports Sent by Receiver"},{"location":"protocol/events-and-timers/#triggered-by-loss-detection","text":"Loss detection is based on Gaps in Sequence Numbers. Detection of a packet loss is triggered with the newly received packet. An offset between the newly arrived packet and the last acknowledged position is calculated. In case the offset is negative, the packet is considered belated, meaning that it was either already acknowledged or dropped by TSBPD as too late to be delivered. Such belated packets are ignored. Documentation states the retransmitted packet is not considered belated Check statistics handling any packets after receiver ACK as belated, regardless of the retransmit flag. Should the re-transmitted packets be ignored? An offset between sequence numbers of the arrived packet and the previously received packet is calculated. If the packet is not the next packet in order, then a loss detection mechanism is triggered. First, a gap in sequence numbers of the consecutively received packets might be due to packet reordering. Sequence numbers that should fill the gap are added to the *RcvLossList* of a socket. Then there is a decision whether a loss report should be sent. A non-zero reorder tolerance (ReorderTolerance <= MaxReorderTolerance) determines if a gap in sequence numbers is allowed. The default value of MaxReorderTolerance is zero, and it can be set with SRTO_LOSSMAXTTL socket option. If ReorderTolerance==0, a loss report is sent immediately for the detected gap. Otherwise, if ReorderTolerance>0, then the detected gap is added to a temporal loss list, with a TTL value equal to current ReorderTolerance value. Each time a DATA packet is received, TTTL of every lost packet in this temporal loss list is decremented by 1. Those packets TODO: Describe ReorderTolerance update logic Example from SRT Periodic NAK Reports showing how a serial loss will be treated. Packets in Transit | Receive Buffer | | Largest sequence number received (4) | New / +---+ +---+ | +---+ +---+---+---+---+---+---+ --- | 9 | --- | 8 | ---> | --->| 7 | + | _ | _ | 4 | 3 | _ | 1 | ---> +---+ +---+ | +---+ | +---+---+---+---+---+---+ | | \\_____/ \\_/ +---+ | +---+ | \\____________/ <--- |NAK| <--- | <---|NAK|-+ Missing packets | 2 | | |5,6| +---+ | +---+","title":"Triggered by Loss Detection"},{"location":"protocol/events-and-timers/#triggered-by-periodic-nak-reports","text":"See also SRT Periodic NAK Reports . By default periodic NAK reports are enabled in live mode (SRTO_TRANSTYPE = SRTT_LIVE), and disabled in file mode (SRTO_TRANSTYPE = SRTT_FILE). The functionality is controlled by SRTO_NAKREPORT socket option. NAKtime is the time to send the next periodic NAK report. When t >= NAKtime and the RcvLossList* * is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList* *). | Receive Buffer | | Largest sequence number received (7) | / | +---+---+---+---+---+---+---+ | --->| 7 | _ | _ | 4 | 3 | _ | 1 | ---> | +---+---+---+---+---+---+---+ | | \\_____/ \\_/ | +-----+ | \\____________/ | <-| NAK |-+ Missing packets | |2,5,6| | +-----+ NAKtime is first initialized when a socket is created, and updated after a connection is established (since SRT v1.3.3, PR #745 ). Regularly NAKtime is updated with the last time a periodic NAK report was sent: NAKtime = t + NAKInt . ISSUE #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? Or at least update the time if there are no losses in the *RcvLossList* . where NAKInt is an interval between periodic NAK reports. Minimum NAK interval is NAKIntmin=300 ms, and it is set at the very beginning of the streaming. NAK interval NAKInt is updated after sending a loss report. The new value is NAKInt = RTT + 4 \u00d7 RTTVar . This value is passed to the CC module. FileCC can update NAKInt based on the reported receiving speed Rrcv (packets per second) and the length of the loss list LOSSlen: NAKInt = RTT + 4 \u00d7 RTTVar + LOSSlen \u00d7 106 / Rrcv. LiveCC will update NAKInt by dividing it by 2: LOSSlen: NAKInt = (RTT + 4 \u00d7 RTTVar) / 2. The minimum value is NAKInt = max(NAKInt, NAKIntmin). NAKtime is a time to send the next periodic NAK report. The time is initialized at CUDT::open() and after a connection is established (PR #745 ). NAKtime is updated with the last time a periodic NAK report was sent. ISSUE #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? When t >= NAKtime and the RcvLossList* * is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList* *).","title":"Triggered by Periodic NAK Reports"},{"location":"protocol/events-and-timers/#packet-retransmission-sender","text":"","title":"Packet Retransmission (Sender)"},{"location":"protocol/events-and-timers/#retransmission-triggered-by-nak-report","text":"A packet is scheduled for retransmission if a sender receives a NAK report from the receiver. A loss report may be triggered either by loss detection, or by periodic NAK reports (see NAK Reports section above).","title":"Retransmission Triggered by NAK Report"},{"location":"protocol/events-and-timers/#blind-retransmission","text":"A blind retransmission is an heuristic mechanism of a sender to trigger packet retransmission without receiving a NAK report from the receiver.","title":"Blind Retransmission"},{"location":"protocol/events-and-timers/#fast-retransmission-fastrexmit","text":"FASTREXMIT mode is enabled by LiveCC when the receiver is not expected to send periodic NAK reports. A condition is triggered based on the LastRspAck time. Timer-triggered condition: t > N \u00d7 (RTT + 4 \u00d7 RTTVar + 2 \u00d7 SYN) + SYN, where SYN=10 ms, and N is a number of such retransmissions since last ACK (also reset if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg). All unacknowledged packets in the sender's buffer are added to the SndLossList and scheduled for retransmission. FASTREXMIT is not present in UDT.","title":"Fast Retransmission (FASTREXMIT)"},{"location":"protocol/events-and-timers/#late-retransmission-laterexmit","text":"TODO: User-defined RTT Describe a scenario with a user-defined RTO value. The LATEREXMIT is the default blind retransmission mode of UDT. LATEREXMIT is triggered by the EXP timer. EXP timer in UDT is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) is used in the implementation. Each time EXP timer is triggered, resend unacknowledged packets currently in the sender's buffer if there are some, otherwise send a KEEPALIVE message. In SRT v1.3.2 and earlier the logic is the same, except that a KEEPALIVE message has its own timer and a timeout of 1 second (see keepalive section above). TODO: Check if excessive KEEPALIVE messages are sent after a retransmission is scheduled.","title":"Late Retransmission (LATEREXMIT)"},{"location":"protocol/overhead/","text":"SRT Protocol Overhead :root { --ion-safe-area-top: 20px; --ion-safe-area-bottom: 22px; } function calcOverhead(Mbps, loss_ratio, latency_xrtt) { const bps = Mbps * 1000000; const MAX_PLD = 1316; const DATA_HDR_BYTES = 24; const ACK_BYTES = 44; const ACKACK_BYTES = 16; const NAK_BYTES = 16 + 4; const data_pkts = Math.ceil(bps / (8 * MAX_PLD)); const data_hdr_bytes = data_pkts * DATA_HDR_BYTES; const ack_pkts = 1000 / 10; // Every 10 ms const ack_bytes = ack_pkts * ACK_BYTES; const ackack_bytes = ack_pkts * ACKACK_BYTES; const lost_pkts = Math.ceil(data_pkts * loss_ratio); const nak_bytes = lost_pkts * NAK_BYTES; // TODO: latency of 1RTT const resend_bytes = lost_pkts * (MAX_PLD + DATA_HDR_BYTES) //console.log(\"Bitrate \" + Mbps + \" num pkts \" + data_pkts + \" lost pkts \" + lost_pkts + \" resend \" + resend_bytes); return { dataHdrBytes: data_hdr_bytes, ackBytes: ack_bytes, ackackBytes: ackack_bytes, nakBytes: nak_bytes, resendBytes: resend_bytes }; } function createDataSet(beginMbps, endMbps, stepMbps, lossRatio = 0) { let bitrates = []; let dataHeaderBits = []; let ackBits = []; let ackackBits = []; let nakBits = []; let resendBits = []; // _.range([start], stop, [step]) // _.range(10); // => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for (let Mbps = beginMbps; Mbps < endMbps; Mbps += stepMbps) { //console.log(Mbps); //const {dataHdrBits, ackBits, ackackBits, nakBits, resendBits} = calcOverhead(Mbps, 0, 0); const {dataHdrBytes, ackBytes, ackackBytes, nakBytes, resendBytes} = calcOverhead(Mbps, lossRatio, 0); bitrates.push(Mbps); dataHeaderBits.push(((8 * dataHdrBytes) / (Mbps * 10000)).toFixed(3)); ackBits.push(((8 * ackBytes) / (Mbps * 10000)).toFixed(3)); ackackBits.push(((8 * ackackBytes) / (Mbps * 10000)).toFixed(3)); nakBits.push(((8 * nakBytes) / (Mbps * 10000)).toFixed(3)); resendBits.push(((8 * resendBytes) / (Mbps * 10000)).toFixed(3)); } //console.log(ackackBits) return { bitratesMbps: bitrates, dataHeaderBits: dataHeaderBits, ackBits: ackBits, ackackBits: ackackBits, nakBits: nakBits, resendBits: resendBits }; } var ctx = document.getElementById(\"stacked-area-chart\").getContext(\"2d\"); const colors = { green: { fill: '#e0eadf', stroke: '#5eb84d', }, lightBlue: { stroke: '#6fccdd', }, darkBlue: { fill: '#92bed2', stroke: '#3282bf', }, purple: { fill: '#8fa8c8', stroke: '#75539e', }, }; function onLossRatioChanged(value) { //console.log(\"New value \" + value); dataSet = createDataSet(1, 30, 1, value / 100); myChart.data.datasets[0].data = dataSet.dataHeaderBits; myChart.data.datasets[1].data = dataSet.ackBits; myChart.data.datasets[2].data = dataSet.ackackBits; myChart.data.datasets[3].data = dataSet.nakBits; myChart.data.datasets[4].data = dataSet.resendBits; //console.log(myChart.data.datasets); myChart.update(); } const dataPackets = Array.from(new Array(5), (val, i)=> calcOverhead(1+ i * 5, 0, 0) ); var dataSet = createDataSet(1, 30, 1); const availableForExisting = [16, 13, 25, 33, 40, 33, 45]; const unavailable = [5, 9, 10, 9, 18, 19, 20]; var myChart = new Chart(ctx, { type: 'line', data: { labels: dataSet.bitratesMbps, datasets: [{ label: \"DATA Header Bits\", fill: true, backgroundColor: colors.purple.fill, pointBackgroundColor: colors.purple.stroke, borderColor: colors.purple.stroke, pointHighlightStroke: colors.purple.stroke, borderCapStyle: 'butt', data: dataSet.dataHeaderBits, }, { label: \"ACK Bits\", fill: true, backgroundColor: colors.darkBlue.fill, pointBackgroundColor: colors.darkBlue.stroke, borderColor: colors.darkBlue.stroke, pointHighlightStroke: colors.darkBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackBits, }, { label: \"ACKACK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.lightBlue.stroke, borderColor: colors.lightBlue.stroke, pointHighlightStroke: colors.lightBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackackBits, }, { label: \"NAK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.nakBits, }, { label: \"Resend Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.resendBits, }] }, options: { showAllTooltips: true, responsive: false, // Can't just just `stacked: true` like the docs say scales: { yAxes: [{ stacked: true, scaleLabel: { display: true, labelString: 'Overhead, %' } }], xAxes: [{ scaleLabel: { display: true, labelString: 'Bitrate, Mbps' } }] }, animation: { duration: 750, }, } }); Loss ratio: Latency (xRTT): TODO $(\".js-range-slider\").ionRangeSlider({ skin: \"round\", grid: true, min: 0, max: 10, step: 1, from: 0, postfix: \" %\" });","title":"SRT Protocol Overhead"},{"location":"protocol/overhead/#srt-protocol-overhead","text":":root { --ion-safe-area-top: 20px; --ion-safe-area-bottom: 22px; } function calcOverhead(Mbps, loss_ratio, latency_xrtt) { const bps = Mbps * 1000000; const MAX_PLD = 1316; const DATA_HDR_BYTES = 24; const ACK_BYTES = 44; const ACKACK_BYTES = 16; const NAK_BYTES = 16 + 4; const data_pkts = Math.ceil(bps / (8 * MAX_PLD)); const data_hdr_bytes = data_pkts * DATA_HDR_BYTES; const ack_pkts = 1000 / 10; // Every 10 ms const ack_bytes = ack_pkts * ACK_BYTES; const ackack_bytes = ack_pkts * ACKACK_BYTES; const lost_pkts = Math.ceil(data_pkts * loss_ratio); const nak_bytes = lost_pkts * NAK_BYTES; // TODO: latency of 1RTT const resend_bytes = lost_pkts * (MAX_PLD + DATA_HDR_BYTES) //console.log(\"Bitrate \" + Mbps + \" num pkts \" + data_pkts + \" lost pkts \" + lost_pkts + \" resend \" + resend_bytes); return { dataHdrBytes: data_hdr_bytes, ackBytes: ack_bytes, ackackBytes: ackack_bytes, nakBytes: nak_bytes, resendBytes: resend_bytes }; } function createDataSet(beginMbps, endMbps, stepMbps, lossRatio = 0) { let bitrates = []; let dataHeaderBits = []; let ackBits = []; let ackackBits = []; let nakBits = []; let resendBits = []; // _.range([start], stop, [step]) // _.range(10); // => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for (let Mbps = beginMbps; Mbps < endMbps; Mbps += stepMbps) { //console.log(Mbps); //const {dataHdrBits, ackBits, ackackBits, nakBits, resendBits} = calcOverhead(Mbps, 0, 0); const {dataHdrBytes, ackBytes, ackackBytes, nakBytes, resendBytes} = calcOverhead(Mbps, lossRatio, 0); bitrates.push(Mbps); dataHeaderBits.push(((8 * dataHdrBytes) / (Mbps * 10000)).toFixed(3)); ackBits.push(((8 * ackBytes) / (Mbps * 10000)).toFixed(3)); ackackBits.push(((8 * ackackBytes) / (Mbps * 10000)).toFixed(3)); nakBits.push(((8 * nakBytes) / (Mbps * 10000)).toFixed(3)); resendBits.push(((8 * resendBytes) / (Mbps * 10000)).toFixed(3)); } //console.log(ackackBits) return { bitratesMbps: bitrates, dataHeaderBits: dataHeaderBits, ackBits: ackBits, ackackBits: ackackBits, nakBits: nakBits, resendBits: resendBits }; } var ctx = document.getElementById(\"stacked-area-chart\").getContext(\"2d\"); const colors = { green: { fill: '#e0eadf', stroke: '#5eb84d', }, lightBlue: { stroke: '#6fccdd', }, darkBlue: { fill: '#92bed2', stroke: '#3282bf', }, purple: { fill: '#8fa8c8', stroke: '#75539e', }, }; function onLossRatioChanged(value) { //console.log(\"New value \" + value); dataSet = createDataSet(1, 30, 1, value / 100); myChart.data.datasets[0].data = dataSet.dataHeaderBits; myChart.data.datasets[1].data = dataSet.ackBits; myChart.data.datasets[2].data = dataSet.ackackBits; myChart.data.datasets[3].data = dataSet.nakBits; myChart.data.datasets[4].data = dataSet.resendBits; //console.log(myChart.data.datasets); myChart.update(); } const dataPackets = Array.from(new Array(5), (val, i)=> calcOverhead(1+ i * 5, 0, 0) ); var dataSet = createDataSet(1, 30, 1); const availableForExisting = [16, 13, 25, 33, 40, 33, 45]; const unavailable = [5, 9, 10, 9, 18, 19, 20]; var myChart = new Chart(ctx, { type: 'line', data: { labels: dataSet.bitratesMbps, datasets: [{ label: \"DATA Header Bits\", fill: true, backgroundColor: colors.purple.fill, pointBackgroundColor: colors.purple.stroke, borderColor: colors.purple.stroke, pointHighlightStroke: colors.purple.stroke, borderCapStyle: 'butt', data: dataSet.dataHeaderBits, }, { label: \"ACK Bits\", fill: true, backgroundColor: colors.darkBlue.fill, pointBackgroundColor: colors.darkBlue.stroke, borderColor: colors.darkBlue.stroke, pointHighlightStroke: colors.darkBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackBits, }, { label: \"ACKACK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.lightBlue.stroke, borderColor: colors.lightBlue.stroke, pointHighlightStroke: colors.lightBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackackBits, }, { label: \"NAK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.nakBits, }, { label: \"Resend Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.resendBits, }] }, options: { showAllTooltips: true, responsive: false, // Can't just just `stacked: true` like the docs say scales: { yAxes: [{ stacked: true, scaleLabel: { display: true, labelString: 'Overhead, %' } }], xAxes: [{ scaleLabel: { display: true, labelString: 'Bitrate, Mbps' } }] }, animation: { duration: 750, }, } });","title":"SRT Protocol Overhead"},{"location":"protocol/congestion-control/","text":"Congestion Control Starting from v1.3.0, SRT provides two types of data transmission: live and file. The mode can be selected via the socket option SRTO_CONGESTION (or more general SRTO_TRANSTYPE option). Live congestion control is used in live transmission mode. In this more the source has a certain rate (either constant or variable). Packets should be transmitted with the same rate as the source. Therefore, the congestion control module does not try to avoid network congestion. It is mainly a reactor on network events. Based on the network conditions (mainly RTT), LiveCC determines when a packet should be considered lost. On the receiving side, liveCC may decide when an ACK is needed prior to ACK timeout. LiveCC also determines the minimum time between consecutive packets are sent. File congestion control is used in file transmission mode. FileCC controls sending pace to avoid network congestion. the only job congestion control module does is to keep sending rate. Useful Links Yunhong Gu. The UDT Congestion Control Algorithm . 2009. Network Congestion Management: Considerations and Techniques","title":"Congestion Control"},{"location":"protocol/congestion-control/#congestion-control","text":"Starting from v1.3.0, SRT provides two types of data transmission: live and file. The mode can be selected via the socket option SRTO_CONGESTION (or more general SRTO_TRANSTYPE option). Live congestion control is used in live transmission mode. In this more the source has a certain rate (either constant or variable). Packets should be transmitted with the same rate as the source. Therefore, the congestion control module does not try to avoid network congestion. It is mainly a reactor on network events. Based on the network conditions (mainly RTT), LiveCC determines when a packet should be considered lost. On the receiving side, liveCC may decide when an ACK is needed prior to ACK timeout. LiveCC also determines the minimum time between consecutive packets are sent. File congestion control is used in file transmission mode. FileCC controls sending pace to avoid network congestion. the only job congestion control module does is to keep sending rate.","title":"Congestion Control"},{"location":"protocol/congestion-control/#useful-links","text":"Yunhong Gu. The UDT Congestion Control Algorithm . 2009. Network Congestion Management: Considerations and Techniques","title":"Useful Links"},{"location":"protocol/congestion-control/file-cc/","text":"File Congestion Control The main goal of File congestion control is to send data at the highest possible rate within the given network conditions. Sending with higher rate than the avalable bandwidth of a link will result in network congestion, forcing huge overhead due to necessity of packet retransmission. Sending with the rate lower, that the available bandwidth, results in underutilization of the network link. FileCC has three operation states: slow start, congestion avoidance and slow down. At the start, there is no information on the network. Congestion control module has to do some probing to determine the available bandwidth and the best sending pace for the normal operation mode - congestion avoidance. In congestion avoidance state, as long as there is no congestion detected (via Loss reports), the sending pace is gradually increased. In case of network congestion, the state is switched to slow down, where the sending pace is reduced to eliminate packet loss in a congested network. Slow Start Slow-start state has an artificial limit on the number of data packets that can be sent before acknowledgment of those segments is received. Slow-start is designed to limit network congestion [1]. File CC starts with 16 DATA packets ( CWND_SIZE=16 ) sent with minimum possible interval. int m_iRCInterval; // SRT Rate control interval Upon ACK Received ACK are processed not more often than every 10 milliseconds ( CUDT::COMM_SYN_INTERVAL_US ). CWND_SIZE is increased to the difference between the acknowledged sequence number since last ACK processing, and the sequence number being acknowledged: CWND_SIZE += LAST_ACK_SEQNO - ACK_SEQNO . If CWND_SIZE exceeds MAX_CWND_SIZE , slow start period ends. MAX_CWND_SIZE=FLOW_WND_SIZE . If delivery rate was reported by the receiver, the inter sending interval is set according to that rate. PKT_SND_PERIOD = 1000000.0 / DELIVERY_RATE where DELIVERY_RATE is filtered with IIR(8) . If delivery rate is not reported, the sending period is set to be PktSndPeriod = CWndSize / (RTT + RCInterval) Upon timers are checked Refer to FileCC::speedupToWindowSize(...) . When CUDT::checkRexmitTimer(...) is called and there is a timeout for the last response from the receiver, then slow start period ends, and the packet send period is set according to the above rules. Congestion Avoidance Upon ACK Upon Loss Report (NACK) References TCP/IP Characteristics. Windows Dev Center. [ WEB ]","title":"File Congestion Control"},{"location":"protocol/congestion-control/file-cc/#file-congestion-control","text":"The main goal of File congestion control is to send data at the highest possible rate within the given network conditions. Sending with higher rate than the avalable bandwidth of a link will result in network congestion, forcing huge overhead due to necessity of packet retransmission. Sending with the rate lower, that the available bandwidth, results in underutilization of the network link. FileCC has three operation states: slow start, congestion avoidance and slow down. At the start, there is no information on the network. Congestion control module has to do some probing to determine the available bandwidth and the best sending pace for the normal operation mode - congestion avoidance. In congestion avoidance state, as long as there is no congestion detected (via Loss reports), the sending pace is gradually increased. In case of network congestion, the state is switched to slow down, where the sending pace is reduced to eliminate packet loss in a congested network.","title":"File Congestion Control"},{"location":"protocol/congestion-control/file-cc/#slow-start","text":"Slow-start state has an artificial limit on the number of data packets that can be sent before acknowledgment of those segments is received. Slow-start is designed to limit network congestion [1]. File CC starts with 16 DATA packets ( CWND_SIZE=16 ) sent with minimum possible interval. int m_iRCInterval; // SRT Rate control interval","title":"Slow Start"},{"location":"protocol/congestion-control/file-cc/#upon-ack-received","text":"ACK are processed not more often than every 10 milliseconds ( CUDT::COMM_SYN_INTERVAL_US ). CWND_SIZE is increased to the difference between the acknowledged sequence number since last ACK processing, and the sequence number being acknowledged: CWND_SIZE += LAST_ACK_SEQNO - ACK_SEQNO . If CWND_SIZE exceeds MAX_CWND_SIZE , slow start period ends. MAX_CWND_SIZE=FLOW_WND_SIZE . If delivery rate was reported by the receiver, the inter sending interval is set according to that rate. PKT_SND_PERIOD = 1000000.0 / DELIVERY_RATE where DELIVERY_RATE is filtered with IIR(8) . If delivery rate is not reported, the sending period is set to be PktSndPeriod = CWndSize / (RTT + RCInterval)","title":"Upon ACK Received"},{"location":"protocol/congestion-control/file-cc/#upon-timers-are-checked","text":"Refer to FileCC::speedupToWindowSize(...) . When CUDT::checkRexmitTimer(...) is called and there is a timeout for the last response from the receiver, then slow start period ends, and the packet send period is set according to the above rules.","title":"Upon timers are checked"},{"location":"protocol/congestion-control/file-cc/#congestion-avoidance","text":"","title":"Congestion Avoidance"},{"location":"protocol/congestion-control/file-cc/#upon-ack","text":"","title":"Upon ACK"},{"location":"protocol/congestion-control/file-cc/#upon-loss-report-nack","text":"","title":"Upon Loss Report (NACK)"},{"location":"protocol/congestion-control/file-cc/#references","text":"TCP/IP Characteristics. Windows Dev Center. [ WEB ]","title":"References"},{"location":"protocol/tsbpd/","text":"TSBPD","title":"TSBPD"},{"location":"protocol/tsbpd/#tsbpd","text":"","title":"TSBPD"},{"location":"protocol/tsbpd/drift-management/","text":"Drift Management When the sender enters \u201cconnected\u201d state it tells the application there is a socket interface that is transmitter-ready. At this point the application can start sending data packets. It adds packets to the SRT sender\u2018s buffer at a certain input rate, from which they are transmitted to the receiver at scheduled times. A synchronized time is required to keep proper sender/receiver buffer levels, taking into account the time zone and round-trip time (up to 2 seconds for satellite links). Considering addition/subtraction round-\u00adoff, and possibly unsynchronized system times, an agreed-\u00adupon time base drifts by a few microseconds every minute. The drift may accumulate over many days to a point where the sender or receiver buffers will overflow or deplete, seriously affecting the quality of the video. SRT has a time management mechanism to compensate for this drift. When a packet is received, SRT determines the difference between the time it was expected and its timestamp. The timestamp is calculated on the receiver side. The RTT tells the receiver how much time it was supposed to take. SRT maintains a reference between the time at the leading edge of the send buffer\u2018s latency window and the corresponding time on the receiver (the present time). This allows conversion to real time to be able to schedule events, based on a local time reference. The receiver samples time drift data and periodically calculates a packet timestamp correction factor, which is applied to each data packet received by adjusting the inter-packet interval. When a packet is received it isn\u2018t given right away to the application. As time advances, the receiver knows the expected time for any missing or dropped packet, and can use this information to fill any \u201choles\u201d in the receive queue with another packet. The receiver uses local time to be able to schedule events \u2014 to determine, for example, if it\u2018s time to deliver a certain packet right away. The timestamps in the packets themselves are just references to the beginning of the session. When a packet is received (with a timestamp from the sender), the receiver makes a reference to the beginning of the session to recalculate its timestamp. The start time is derived from the local time at the moment that the session is connected. A packet timestamp equals \u201cnow\u201d minus \u201cStartTime\u201d, where the latter is the point in time when the socket was created.","title":"Drift Management"},{"location":"protocol/tsbpd/drift-management/#drift-management","text":"When the sender enters \u201cconnected\u201d state it tells the application there is a socket interface that is transmitter-ready. At this point the application can start sending data packets. It adds packets to the SRT sender\u2018s buffer at a certain input rate, from which they are transmitted to the receiver at scheduled times. A synchronized time is required to keep proper sender/receiver buffer levels, taking into account the time zone and round-trip time (up to 2 seconds for satellite links). Considering addition/subtraction round-\u00adoff, and possibly unsynchronized system times, an agreed-\u00adupon time base drifts by a few microseconds every minute. The drift may accumulate over many days to a point where the sender or receiver buffers will overflow or deplete, seriously affecting the quality of the video. SRT has a time management mechanism to compensate for this drift. When a packet is received, SRT determines the difference between the time it was expected and its timestamp. The timestamp is calculated on the receiver side. The RTT tells the receiver how much time it was supposed to take. SRT maintains a reference between the time at the leading edge of the send buffer\u2018s latency window and the corresponding time on the receiver (the present time). This allows conversion to real time to be able to schedule events, based on a local time reference. The receiver samples time drift data and periodically calculates a packet timestamp correction factor, which is applied to each data packet received by adjusting the inter-packet interval. When a packet is received it isn\u2018t given right away to the application. As time advances, the receiver knows the expected time for any missing or dropped packet, and can use this information to fill any \u201choles\u201d in the receive queue with another packet. The receiver uses local time to be able to schedule events \u2014 to determine, for example, if it\u2018s time to deliver a certain packet right away. The timestamps in the packets themselves are just references to the beginning of the session. When a packet is received (with a timestamp from the sender), the receiver makes a reference to the beginning of the session to recalculate its timestamp. The start time is derived from the local time at the moment that the session is connected. A packet timestamp equals \u201cnow\u201d minus \u201cStartTime\u201d, where the latter is the point in time when the socket was created.","title":"Drift Management"},{"location":"protocol/tsbpd/latency/","text":"SRT Latency SRT has an end-to-end latency between the time a packet is given to SRT with srt_sendmsg(...) and the time this very packet is received from SRT via srt_recvmsg(...) . The timing diagram illustrates those key latency points with TSBPD enabled (live mode). End-to-end latency The actual latency on the link will roughly be SRTO_RCVLATENCY + 1/2 \u00d7 RTT 0 , where RTT 0 is the RTT value during the handshake. Packet Delivery Time Packet delivery time is the time point, estimated by the receiver, when a packet should be given (delivered) to the upstream application (via srt_recvmsg(...) ). It consists of the TsbPdTimeBase - the base time difference between sender's and receiver's clock, receiver's buffer delay TsbPdDelay , a timestamp of a data packet PKT_TIMESTAMP , and a time drift Drift . PktTsbPdTime = TsbPdTimeBase + TsbPdDelay + PKT_TIMESTAMP + Drift TSBPD Base Time TsbPdTimeBase is the base time difference between local clock of the receiver, and the clock used by the sender to timestamp packets being sent. A unit of measurement is microseconds. Initial value The value of TsbPdTimeBase is initialized at the time of the handshake request ( HSREQ ) is received. TsbPdTimeBase = T_NOW - HSREQ_TIMESTAMP . This value should roughly correspond to the one-way delay ( ~RTT/2 ). TSBPD Wrapping Period The value of TsbPdTimeBase can be updated during the TSBPD wrapping period. The period starts 30 seconds before reaching the maximum timestamp value of a packet ( CPacket::MAX_TIMESTAMP ), and ends whens the timestamp of the received packet is within [30; 60] seconds. CPacket::MAX_TIMESTAMP = 0xFFFFFFFF , or maximum 32-bit unsigned integer value. The value is in microseconds, which corresponds to 1 hour 11 minutes and 35 seconds (01:11:35). In other words, TSBPD time wrapping happens every 01:11:35. During this wrapping period, a packet may have a timestamp close to CPacket::MAX_TIMESTAMP , as well as close to 0 . Both cases are handled. In the first case, the current value of TsbPdTimeBase is used. In the seconds case, TsbPdTimeBase + CPacket::MAX_TIMESTAMP + 1 is used to calculate TSBPD time of a packet. The wrapping period ends when the timestamp of the received packet is within the interval [30; 60] seconds. The updated value will be TsbPdTimeBase += CPacket::MAX_TIMESTAMP + 1 . Time Drift The value of TsbPdTimeBase can be updated by the DriftTracer. Time Drift Sample Upon receipt of an ACKACK packet, the timestamp of this control packet is used as a sample for drift tracing. ACKACK timestamp is expected to be half the round-trip time ago ( RTT/2 ). The drift time DRIFT is calculated from the current time T_NOW ; the TSBPD base time TsbPdTimeBase ; and the timestamp ACKACK_TIMESTAMP of the received ACKACK packet. DRIFT = T_NOW - (TsbPdTimeBase + ACKACK_TIMESTAMP) The base time should stay in sync with T_NOW - T_SENDER , and should roughly correspond to ~RTT/2 . The value of ACKACK_TIMESTAMP should represent T_SENDER , and be ~RTT/2 in the past. Therefore, the above equation can be considered as DRIFT = T_NOW - (T_NOW - T_SENDER + T_SENDER) -> 0 if the link latency remains constant. Assuming that the link latency is constant (RTT=const), the only cause of the drift fluctuations should be clock inaccuracy. Drift Tracer should consider RTT Time drift sample does not take RTT fluctuations into account. Instead an increase of RTT will be treated as a time drift. See issue 753 . Drift Tracing and Adjustment Drift tracing is based on accumulating the sum of drift samples. DriftSum - the sum of the time drift samples on a MAX_SPAN number of samples. DriftSpan is the current number of accumulated samples. The default value of MAX_SPAN is 1000 samples. The default value of MAX_DRIFT is 5000 \u03bcs (5 ms). The default value of CLEAR_ON_UPDATE is true . On each DriftSpan sample, the average drift value Drift is updated as Drift = DriftSum / DriftSpan . The values of DriftSpan and DriftSum are reset to 0. If the absolute value of the Drift exceeds MAX_DRIFT ( |Drift| > MAX_DRIFT ), the remainder goes to OverDrift value. The value of OverDrift is used to update the TsbPdTimeBase . In pseudo-code it looks like this: bool update(int64_t driftval) { DriftSum += driftval; ++DriftSpan; if (m_uDriftSpan < MAX_SPAN) return false; if (CLEAR_ON_UPDATE) Overdrift = 0; Drift = DriftSum / DriftSpan; DriftSum = 0; DriftSpan = 0; if (std::abs(Drift) > MAX_DRIFT) { Overdrift = Drift < 0 ? -MAX_DRIFT : MAX_DRIFT; Drift -= Overdrift; } // Drift value was updated return true; } Consider RTTVar before changin the Drift value RTTVar expresses the variation of RTT values over time. Those variations should be considered when Drift is updated. Class DriftTracer The DriftTracer class has the following prototype. template<unsigned MAX_SPAN, int MAX_DRIFT, bool CLEAR_ON_UPDATE = true> class DriftTracer { public: DriftTracer(); public: bool update(int64_t driftval); int64_t drift() const; int64_t overdrift() const; };","title":"SRT Latency"},{"location":"protocol/tsbpd/latency/#srt-latency","text":"SRT has an end-to-end latency between the time a packet is given to SRT with srt_sendmsg(...) and the time this very packet is received from SRT via srt_recvmsg(...) . The timing diagram illustrates those key latency points with TSBPD enabled (live mode). End-to-end latency The actual latency on the link will roughly be SRTO_RCVLATENCY + 1/2 \u00d7 RTT 0 , where RTT 0 is the RTT value during the handshake.","title":"SRT Latency"},{"location":"protocol/tsbpd/latency/#packet-delivery-time","text":"Packet delivery time is the time point, estimated by the receiver, when a packet should be given (delivered) to the upstream application (via srt_recvmsg(...) ). It consists of the TsbPdTimeBase - the base time difference between sender's and receiver's clock, receiver's buffer delay TsbPdDelay , a timestamp of a data packet PKT_TIMESTAMP , and a time drift Drift . PktTsbPdTime = TsbPdTimeBase + TsbPdDelay + PKT_TIMESTAMP + Drift","title":"Packet Delivery Time"},{"location":"protocol/tsbpd/latency/#tsbpd-base-time","text":"TsbPdTimeBase is the base time difference between local clock of the receiver, and the clock used by the sender to timestamp packets being sent. A unit of measurement is microseconds.","title":"TSBPD Base Time"},{"location":"protocol/tsbpd/latency/#initial-value","text":"The value of TsbPdTimeBase is initialized at the time of the handshake request ( HSREQ ) is received. TsbPdTimeBase = T_NOW - HSREQ_TIMESTAMP . This value should roughly correspond to the one-way delay ( ~RTT/2 ).","title":"Initial value"},{"location":"protocol/tsbpd/latency/#tsbpd-wrapping-period","text":"The value of TsbPdTimeBase can be updated during the TSBPD wrapping period. The period starts 30 seconds before reaching the maximum timestamp value of a packet ( CPacket::MAX_TIMESTAMP ), and ends whens the timestamp of the received packet is within [30; 60] seconds. CPacket::MAX_TIMESTAMP = 0xFFFFFFFF , or maximum 32-bit unsigned integer value. The value is in microseconds, which corresponds to 1 hour 11 minutes and 35 seconds (01:11:35). In other words, TSBPD time wrapping happens every 01:11:35. During this wrapping period, a packet may have a timestamp close to CPacket::MAX_TIMESTAMP , as well as close to 0 . Both cases are handled. In the first case, the current value of TsbPdTimeBase is used. In the seconds case, TsbPdTimeBase + CPacket::MAX_TIMESTAMP + 1 is used to calculate TSBPD time of a packet. The wrapping period ends when the timestamp of the received packet is within the interval [30; 60] seconds. The updated value will be TsbPdTimeBase += CPacket::MAX_TIMESTAMP + 1 .","title":"TSBPD Wrapping Period"},{"location":"protocol/tsbpd/latency/#time-drift","text":"The value of TsbPdTimeBase can be updated by the DriftTracer.","title":"Time Drift"},{"location":"protocol/tsbpd/latency/#time-drift-sample","text":"Upon receipt of an ACKACK packet, the timestamp of this control packet is used as a sample for drift tracing. ACKACK timestamp is expected to be half the round-trip time ago ( RTT/2 ). The drift time DRIFT is calculated from the current time T_NOW ; the TSBPD base time TsbPdTimeBase ; and the timestamp ACKACK_TIMESTAMP of the received ACKACK packet. DRIFT = T_NOW - (TsbPdTimeBase + ACKACK_TIMESTAMP) The base time should stay in sync with T_NOW - T_SENDER , and should roughly correspond to ~RTT/2 . The value of ACKACK_TIMESTAMP should represent T_SENDER , and be ~RTT/2 in the past. Therefore, the above equation can be considered as DRIFT = T_NOW - (T_NOW - T_SENDER + T_SENDER) -> 0 if the link latency remains constant. Assuming that the link latency is constant (RTT=const), the only cause of the drift fluctuations should be clock inaccuracy. Drift Tracer should consider RTT Time drift sample does not take RTT fluctuations into account. Instead an increase of RTT will be treated as a time drift. See issue 753 .","title":"Time Drift Sample"},{"location":"protocol/tsbpd/latency/#drift-tracing-and-adjustment","text":"Drift tracing is based on accumulating the sum of drift samples. DriftSum - the sum of the time drift samples on a MAX_SPAN number of samples. DriftSpan is the current number of accumulated samples. The default value of MAX_SPAN is 1000 samples. The default value of MAX_DRIFT is 5000 \u03bcs (5 ms). The default value of CLEAR_ON_UPDATE is true . On each DriftSpan sample, the average drift value Drift is updated as Drift = DriftSum / DriftSpan . The values of DriftSpan and DriftSum are reset to 0. If the absolute value of the Drift exceeds MAX_DRIFT ( |Drift| > MAX_DRIFT ), the remainder goes to OverDrift value. The value of OverDrift is used to update the TsbPdTimeBase . In pseudo-code it looks like this: bool update(int64_t driftval) { DriftSum += driftval; ++DriftSpan; if (m_uDriftSpan < MAX_SPAN) return false; if (CLEAR_ON_UPDATE) Overdrift = 0; Drift = DriftSum / DriftSpan; DriftSum = 0; DriftSpan = 0; if (std::abs(Drift) > MAX_DRIFT) { Overdrift = Drift < 0 ? -MAX_DRIFT : MAX_DRIFT; Drift -= Overdrift; } // Drift value was updated return true; } Consider RTTVar before changin the Drift value RTTVar expresses the variation of RTT values over time. Those variations should be considered when Drift is updated.","title":"Drift Tracing and Adjustment"},{"location":"protocol/tsbpd/latency/#class-drifttracer","text":"The DriftTracer class has the following prototype. template<unsigned MAX_SPAN, int MAX_DRIFT, bool CLEAR_ON_UPDATE = true> class DriftTracer { public: DriftTracer(); public: bool update(int64_t driftval); int64_t drift() const; int64_t overdrift() const; };","title":"Class DriftTracer"}]}